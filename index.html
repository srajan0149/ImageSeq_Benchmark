<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>CS613 — Assignment 3</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <header class="site-header">
        <div class="wrap header-grid">
            <div class="brand">
                <h1>CS613 · Assignment 3</h1>
                <p class="sub">ImageSequence — Visual-Temporal Reasoning Benchmark</p>
            </div>
            <nav class="nav">
                <a href="#project overview">Project Overview</a>
                <a href="#baselines">Baselines</a>
                <a href="#dataset">Dataset</a>
                <a href="#implementation">Implementation</a>
                <a href="#management">Management</a>
                <a href="#results">Results</a>
                <a href="#impact_&_limitations">Impact & Limitations</a>
            </nav>
        </div>
        <div class="authors wrap center">
            <strong>Authors:</strong> Dhruv Goel, Jeet Joshi, Naren Kumar S., Pranav, Rahul Khichar, Sai Krishna,
            Simran, Srajan Dehariya
        </div>
    </header>

    <main class="wrap-wide">

        <section id="project_overview" class="hero card">
            <div class="hero-left">
                <h2>Project Overview</h2>
                <p>Benchmark to evaluate multimodal models on ordering shuffled image sequences using a reference image
                    and a short textual context. The task requires the model to understand how events unfold over time
                    and rearrange unordered images into their correct chronological order. The benchmark focuses on
                    visual–temporal reasoning, a capability where many current MLLMs still struggle. It spans diverse
                    domains such as Daily Routine, Culture, Sports, Nature, and Historical Events, ensuring a wide
                    variety of event types and visual patterns. Each instance includes one reference image that serves
                    as the anchor point, four subsequent event frames, and a textual description that provides narrative
                    context, enabling the model to infer causal and temporal relationships. This benchmark highlights
                    the gap between visual recognition and true temporal understanding, pushing models beyond static
                    perception toward sequence-level reasoning.</p>
            </div>
            <div class="hero-right">
                <h3>Mentor Feedback</h3>
                <div class="editable-box">
                    <ul>
                        <li>Less knowledge about existing benchmarks mentioned in the paper.</li>
                        <li>Didn't know the mathematics behind the metrics used like ROUGE, BLEU, bertscore and chrF++.
                        </li>
                        <li>Didn't have reasoning for the patterns in the results.</li>
                        <li>Missing contribution in the Assignment 2.</li>
                        <li>A lot of spelling and grammatical mistakes.</li>
                        <li>In meeting mostly we asked about the expected results from us and how to approach the
                            problem.</li>
                        <li>From the suggestions we got we implemented them in our work.</li>
                    </ul>
                </div>
                <h3>Ideas & Novelties</h3>
                <div class="editable-box-2">Introduces temporal-ordering benchmark enabling causal and narrative
                    sequencing evaluation in MLLMs.</div>
            </div>
        </section>

        <section id="baselines" class="card">
            <h2>Baselines & State-of-the-art</h2>

            <h3>State-of-the-art</h3>
            <ul>
                <li>We are the first to do benchmarking on this task so there is no state-of-the-art and no existing
                    baseline for this novelty.</li>
                <li>Our work is different from existing work as no one has converted an action into 4 frames and then
                    performed temporal ordering with a reference image and text in a zero-shot setting.</li>
                <li>Most existing tasks are like Jigsaw puzzle solving and 24 frame classification.</li>
            </ul>

            <h3>Random Baseline: 50%</h3>

            <h3 class="bold">Evaluated models:</h3>
            <ul class="model-list">
                <li>InternVL3-8B</li>
                <li>Ovis2-16B</li>
                <li>Ovis2-8B</li>
                <li>Ovis2-4B</li>
                <li>Qwen2.5-VL-7B-Instruct</li>
            </ul>
        </section>

        <section id="dataset" class="card">
            <h2>Dataset & Samples</h2>
            <p>The dataset consists of 1 reference image, 4 next-stage event images, and 1 textual description.</p>

            <h3>Nature</h3>

            <div class="gallery-grid-5">
                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Nature Reference.jpg" alt="Reference Image"
                            height="130"></div>
                    <p class="caption">Reference</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Nature frame 1.jpg" alt="Frame 1" height="130"></div>
                    <p class="caption">Next Frame 1</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Nature frame 2.jpg" alt="Frame 2" height="130"></div>
                    <p class="caption">Next Frame 2</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Nature frame 3.jpg" alt="Frame 3" height="130"></div>
                    <p class="caption">Next Frame 3</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Nature frame 4.jpg" alt="Frame 4" height="130"></div>
                    <p class="caption">Next Frame 4</p>
                </div>
            </div>

            <h4>Description</h4>
            <div class="editable-box">A Flower picture</div>

            <h3>Sports</h3>
            <div class="gallery-grid-5">
                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Sports Reference.jpg" alt="Reference Image"
                            height="130"></div>
                    <p class="caption">Reference</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Sports frame 1.jpg" alt="Frame 1" height="130"></div>
                    <p class="caption">Next Frame 1</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Sports frame 2.jpg" alt="Frame 2" height="130"></div>
                    <p class="caption">Next Frame 2</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Sports frame 3.jpg" alt="Frame 3" height="130"></div>
                    <p class="caption">Next Frame 3</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Sports frame 4.jpg" alt="Frame 4" height="130"></div>
                    <p class="caption">Next Frame 4</p>
                </div>
            </div>

            <h4>Description</h4>

            <div class="editable-box">Fielder Catching a ball</div>

            <h3>Historical Events</h3>
            <div class="gallery-grid-5">
                <div class="img-card">
                    <div class="img-placeholder"><img src="images/History Reference.jpg" alt="Reference Image"
                            height="130"></div>
                    <p class="caption">Reference</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/History frame 1.jpg" alt="Frame 1" height="130"></div>
                    <p class="caption">Next Frame 1</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/History frame 2.jpg" alt="Frame 2" height="130"></div>
                    <p class="caption">Next Frame 2</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/History frame 3.jpg" alt="Frame 3" height="130"></div>
                    <p class="caption">Next Frame 3</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/History frame 4.jpg" alt="Frame 4" height="130"></div>
                    <p class="caption">Next Frame 4</p>
                </div>
            </div>

            <h4>Description</h4>
            <div class="editable-box">History of Greece</div>

            <h3>Culture</h3>
            <div class="gallery-grid-5">
                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Culture Reference.jpg" alt="Reference Image"
                            height="130"></div>
                    <p class="caption">Reference</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Culture frame 1.jpg" alt="Frame 1" height="130"></div>
                    <p class="caption">Next Frame 1</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Culture frame 2.jpg" alt="Frame 2" height="130"></div>
                    <p class="caption">Next Frame 2</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Culture frame 3.jpg" alt="Frame 3" height="130"></div>
                    <p class="caption">Next Frame 3</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Culture frame 4.jpg" alt="Frame 4" height="130"></div>
                    <p class="caption">Next Frame 4</p>
                </div>
            </div>

            <h4>Description</h4>
            <div class="editable-box">Post-Ceremony of Hindu Wedding Guyanese</div>

            <h3>Daily Routine</h3>
            <div class="gallery-grid-5">
                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Daily Routine Reference.jpg" alt="Reference Image"
                            height="130"></div>
                    <p class="caption">Reference</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Daily Routine frame 1.jpg" alt="Frame 1" height="130">
                    </div>
                    <p class="caption">Next Frame 1</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Daily Routine frame 2.jpg" alt="Frame 2" height="130">
                    </div>
                    <p class="caption">Next Frame 2</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Daily Routine frame 3.jpg" alt="Frame 3" height="130">
                    </div>
                    <p class="caption">Next Frame 3</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Daily Routine frame 4.jpg" alt="Frame 4" height="130">
                    </div>
                    <p class="caption">Next Frame 4</p>
                </div>
            </div>

            <h4>Description</h4>
            <div class="editable-box">Waking up</div>
        </section>

        <section id="implementation" class="card">
            <h2>Implementation Plan & Pipeline</h2>
            <div class="center-img">
                <img src="images/Pipeline.jpg" alt="Implementation Plan and Pipeline" width="500">
            </div>

            <h3>Ablation Table</h3>
            <table class="striped">
                <thead>
                    <tr>
                        <th class="center">Variant</th>
                        <th class="center">Feature</th>
                        <th class="center">Pairwise Mean Accuracy (in %)</th>
                        <th class="center">Pairwise Median Accuracy (in %)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="center">Full model</td>
                        <td class="center">Ref. Image + Description + Unordered Frames</td>
                        <td class="center">47.95</td>
                        <td class="center">48.00</td>
                    </tr>
                </tbody>
            </table>

            <h3>Comparison with similar benchmarks</h3>
            <table class="striped">
                <thead>
                    <tr>
                        <th class="center">Name</th>
                        <th class="center">Task</th>
                        <th class="center">Mean Accuracy (in %)</th>
                        <th class="center">Random Baseline (in %)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="center">ImageSequence</td>
                        <td class="center">Visual-Temporal Reasoning</td>
                        <td class="center">47.95</td>
                        <td class="center">50.00</td>
                    </tr>
                    <tr>
                        <td class="center">Shuffle & Learn (2016)</td>
                        <td class="center">Action recognition on the UCF101 dataset</td>
                        <td class="center">50.20</td>
                        <td class="center">38.60</td>
                    </tr>
                    <tr>
                        <td class="center">Jigsaw Puzzle (2016)</td>
                        <td class="center">1000-class puzzle prediction</td>
                        <td class="center">78.20</td>
                        <td class="center">0.10</td>
                    </tr>
                    <tr>
                        <td class="center">Order Prediction (2017)</td>
                        <td class="center">24-class frame order prediction</td>
                        <td class="center">60.30</td>
                        <td class="center">4.17</td>
                    </tr>
                </tbody>
            </table>

            <h3>System Efforts Required</h3>
            <div class="editable-box">Due to the substantial size of the models, real-time evaluation is not feasible on
                our system. Therefore, we are demonstrating the pre-computed results.
            </div>

            <h3>Demo</h3>
            <h4>Input:</h4>

            <h5>1. Reference Image:</h5>
            <div class="gallery-grid-5">
                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Nature Reference.jpg" alt="Reference Image"
                            height="130">
                    </div>
                </div>
            </div>

            <h5>2. Description:</h5>
            <div class="editable-box">A Flower picture</div>

            <h5>3. Shuffled Image Sequence [4, 2, 1, 3]:</h5>
            <div class="gallery-grid-5">
                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Nature frame 4.jpg" alt="Frame 4" height="130"></div>
                    <p class="caption">Image 4</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Nature frame 2.jpg" alt="Frame 3" height="130"></div>
                    <p class="caption">Image 2</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Nature frame 1.jpg" alt="Frame 1" height="130"></div>
                    <p class="caption">Image 1</p>
                </div>

                <div class="img-card">
                    <div class="img-placeholder"><img src="images/Nature frame 3.jpg" alt="Frame 2" height="130"></div>
                    <p class="caption">Image 3</p>
                </div>
            </div>

            <h4>Output:</h4>

            <table class="striped">
                <thead>
                    <tr>
                        <th class="center" style="width: 15%;">Model</th>
                        <th class="center" style="width: 15%;">Sequencing</th>
                        <th class="center" style="width: 55%;">Reason</th>
                        <th class="center" style="width: 15%;">Pairwise Accuracy (in %)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="center">InternVL3-8B</td>
                        <td class="center">[4,3,1,2]</td>
                        <td class="center">The sequence follows the blooming stage of the flowers, starting from the
                            most closed buds to the fully bloomed ones, depicted in a logical progression.</td>
                        <td class="center">83.33</td>
                    </tr>
                    <tr>
                        <td class="center">Ovis2-16B</td>
                        <td class="center">[3,2,1,4]</td>
                        <td class="center">The sequence follows the natural progression of a flowering branch, starting
                            with the blossoms in full bloom, semi-closed blooms, buds, and ending with the onset of
                            blossoms, illustrating the lifecycle of flowering.</td>
                        <td class="center">83.33</td>
                    </tr>
                    <tr>
                        <td class="center">Ovis2-8B</td>
                        <td class="center">[2,3,4,1]</td>
                        <td class="center">This sequence starts with the branch in a state of closed buds, progresses
                            through images with more buds opening and fewer closed, and culminates in images with fully
                            opened white flowers. It accurately represents the natural process of buds opening.</td>
                        <td class="center">16.67</td>
                    </tr>
                    <tr>
                        <td class="center">Ovis2-4B</td>
                        <td class="center">[3,1,4,2]</td>
                        <td class="center">The sequence of images appears to represent the progression of a cherry
                            blossom's life cycle. The first image (1) shows a branch with blooming white flowers, which
                            progresses to another image (3) showing buds, indicating early stages of blooming. Finally,
                            the sequence culminates in an image (2) with dried flowers, symbolizing the end of the
                            flowering period.</td>
                        <td class="center">50.00</td>
                    </tr>
                    <tr>
                        <td class="center">Qwen2.5-VL-7B</td>
                        <td class="center">[2,1,4,3]</td>
                        <td class="center">The progression from full bloom to buds indicates the natural cycle of
                            flowering.</td>
                        <td class="center">33.33</td>
                    </tr>
                </tbody>
            </table>

        </section>

        <section id="management" class="card">
            <div>
                <h2>Project Management</h2>

                <h3>Novel Solution Proposed</h3>
                <p>We proposed the novel solutions by first identifying a clear gap in existing research on multimodal
                    and temporal reasoning. While many models today can understand single images or perform basic
                    visual–text tasks, we noticed that very few systems are evaluated on their ability to reason about
                    event progression or temporal order from unordered images. Most existing tasks focus on static
                    recognition or only verify simple ordering patterns, without requiring full sequence reconstruction
                    or multimodal understanding.</p>

                <p>Through discussions with our mentor, we realized that there was no benchmark that asked a model to:
                </p>
                <ul>
                    <li>Reorder a set of shuffled event frames.</li>
                    <li>Use a reference image and text as the anchor of the sequence.</li>
                </ul>

                <p>This gap motivated us to design a benchmark that goes beyond static image interpretation and tests
                    deeper temporal reasoning abilities. Our solution combines different domains evaluated on different
                    MLLMs.</p>


                <h3>Compute Resources</h3>
                <div class="editable-box">
                    <ul>
                        <li>RAM: 48 GB of VRAM (GPU RAM)</li>
                        <li>GPUs: NVIDIA L40S</li>
                        <li>Storage: 300 GB of Disk Space</li>
                    </ul>
                </div>

                <h3>Division of Work</h3>
                <table class="striped authors-table">
                    <thead>
                        <tr>
                            <th style="width: 30%;">Author</th>
                            <th style="width: 70%;">Contribution</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="center">Dhruv Goel</td>
                            <td class="center">Code reading, dataset curation and website development</td>
                        </tr>
                        <tr>
                            <td class="center">Jeet Joshi</td>
                            <td class="center">Code reading and dataset curation</td>
                        </tr>
                        <tr>
                            <td class="center">Naren Kumar S.</td>
                            <td class="center">Novelty proposed, literature review and paper writing</td>
                        </tr>
                        <tr>
                            <td class="center">Pranav</td>
                            <td class="center">Novelty proposed and dataset curation</td>
                        </tr>
                        <tr>
                            <td class="center">Rahul Khichar</td>
                            <td class="center">Paper writing, dataset curation and metric calculation</td>
                        </tr>
                        <tr>
                            <td class="center">Sai Krishna</td>
                            <td class="center">Novelty proposed and dataset curation</td>
                        </tr>
                        <tr>
                            <td class="center">Simran</td>
                            <td class="center">Paper writing, dataset curation and report writing</td>
                        </tr>
                        <tr>
                            <td class="center">Srajan Dehariya</td>
                            <td class="center">Programming and executing of the codes on the server and paper writing
                            </td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <section id="results" class="card">
            <h2>Results & Analysis</h2>

            <div class="results-grid">
                <div class="result-chart">
                    <img src="images/Domain-wise-Mean-Scores-per-Model.jpeg" height="280">
                </div>
                <div class="result-chart">
                    <img src="images/Model-wise-Mean-Scores-per-Domain.jpeg" height="280">
                </div>
            </div>

            <h2> Random Baseline : 50.00% </h2>

            <h3>Pairwise Mean Accuracy (in %)</h3>
            <table class="striped">
                <thead>
                    <tr>
                        <th class="center">Model</th>
                        <th class="center">Culture</th>
                        <th class="center">Daily Routine</th>
                        <th class="center">Historical Events</th>
                        <th class="center">Nature</th>
                        <th class="center">Sports</th>
                        <th class="center">Overall</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="center">InternVL3-8B</td>
                        <td class="center">48.83</td>
                        <td class="center">61.87</td>
                        <td class="center">43.71</td>
                        <td class="center">41.58</td>
                        <td class="center">39.33</td>
                        <td class="center">44.47</td>
                    </tr>
                    <tr>
                        <td class="center">Ovis2-16B</td>
                        <td class="center">49.32</td>
                        <td class="center">63.33</td>
                        <td class="center">48.30</td>
                        <td class="center">46.10</td>
                        <td class="center">48.54</td>
                        <td class="center">48.98</td>
                    </tr>
                    <tr>
                        <td class="center">Ovis2-8B</td>
                        <td class="center">45.50</td>
                        <td class="center">58.67</td>
                        <td class="center">50.00</td>
                        <td class="center">46.67</td>
                        <td class="center">47.71</td>
                        <td class="center">48.27</td>
                    </tr>
                    <tr>
                        <td class="center">Ovis2-4B</td>
                        <td class="center">48.87</td>
                        <td class="center">65.33</td>
                        <td class="center">45.64</td>
                        <td class="center">46.17</td>
                        <td class="center">47.92</td>
                        <td class="center">48.27</td>
                    </tr>
                    <tr>
                        <td class="center">Qwen2.5-VL-7B</td>
                        <td class="center">49.32</td>
                        <td class="center">35.33</td>
                        <td class="center">48.30</td>
                        <td class="center">54.83</td>
                        <td class="center">50.00</td>
                        <td class="center">49.77</td>
                    </tr>
                </tbody>
            </table>
            <h3>Pairwise Median Accuracy (in %)</h3>
            <table class="striped">
                <thead>
                    <tr>
                        <th class="center">Model</th>
                        <th class="center">Culture</th>
                        <th class="center">Daily Routine</th>
                        <th class="center">Historical Events</th>
                        <th class="center">Nature</th>
                        <th class="center">Sports</th>
                        <th class="center">Overall</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="center">InternVL3-8B</td>
                        <td class="center">50.00</td>
                        <td class="center">66.67</td>
                        <td class="center">50.00</td>
                        <td class="center">33.33</td>
                        <td class="center">40.00</td>
                        <td class="center">40.00</td>
                    </tr>
                    <tr>
                        <td class="center">Ovis2-16B</td>
                        <td class="center">50.00</td>
                        <td class="center">66.67</td>
                        <td class="center">50.00</td>
                        <td class="center">50.00</td>
                        <td class="center">50.00</td>
                        <td class="center">50.00</td>
                    </tr>
                    <tr>
                        <td class="center">Ovis2-8B</td>
                        <td class="center">50.00</td>
                        <td class="center">66.67</td>
                        <td class="center">50.00</td>
                        <td class="center">50.00</td>
                        <td class="center">50.00</td>
                        <td class="center">50.00</td>
                    </tr>
                    <tr>
                        <td class="center">Ovis2-4B</td>
                        <td class="center">50.00</td>
                        <td class="center">66.67</td>
                        <td class="center">50.00</td>
                        <td class="center">50.00</td>
                        <td class="center">50.00</td>
                        <td class="center">50.00</td>
                    </tr>
                    <tr>
                        <td class="center">Qwen2.5-VL-7B</td>
                        <td class="center">50.00</td>
                        <td class="center">33.33</td>
                        <td class="center">50.00</td>
                        <td class="center">66.67</td>
                        <td class="center">33.33</td>
                        <td class="center">50.00</td>
                    </tr>
                </tbody>
            </table>

            <h3>Interpretation</h3>
            <div class="editable-box">
                <ul>
                    <li>Most models are good at image ordering of daily routines, likely because these models are mostly
                        trained on daily activities.</li>
                    <li>Qwen2.5-VL-7B has the highest mean accuracy but it is the only model that performs poorly at
                        image ordering
                        of daily routines.</li>
                    <li>InternVL3-8B has been the worst performing model, possibly because it is not trained for these
                        types of tasks.
                    </li>
                    <li>Ovis2-16B, Ovis2-8B and Ovis2-4B gave almost similar results because they are all trained on
                        similar dataset.</li>
                    <li>The sports category has the lowest mean score because in sports, people are in motion and frame
                        changes happen very quickly. The images might also be a little bit hazy because of this.
                    </li>
                </ul>
            </div>
        </section>

        <section id="impact_&_limitations" class="card">
            <h2>Impact & Limitations</h2>

            <h3>Impact</h3>
            <p>
                This benchmark provides a new way to evaluate how well multimodal models understand temporal
                progression, causal relationships,
                and narrative structure from unordered images. By combining a reference image, multiple event frames,
                and textual context,
                it enables a deeper assessment of visual–temporal reasoning than conventional static-image tasks. The
                benchmark highlights
                where current MLLMs struggle, especially in reasoning beyond object recognition, and helps guide the
                development of more
                context-aware and sequence-aware models.
            </p>

            <h3>Limitations</h3>
            <ul>
                <li>The dataset has covered very few domains, so it should be expanded.</li>
                <li>The current version of the benchmark focuses mainly on short, simple event sequences.</li>
                <li>It should also be evaluated on other open-source MLLMs.</li>
                <li>Additionally, the annotation process relies on manual selection of key frames, which may introduce
                    subjective bias. There should be multi-annotator agreement.</li>
            </ul>

            <h3>Future Work</h3>
            <ul>
                <li>Expanding the dataset.</li>
                <li>Extend the dataset to longer, more complex multi-step events.</li>
                <li>Evaluate on more proprietary MLLMs alongside open-source models.</li>
                <li>Explore automated frame selection and annotation pipelines.</li>
                <li>Can be expanded on temporal reasoning for ordering different videos and audios.</li>
            </ul>

        </section>

    </main>

    <footer class="site-footer">
        <div class="wrap footer-grid">
            <div>Prepared for CS613 • IIT Gandhinagar</div>
        </div>
    </footer>

</body>

</html>
